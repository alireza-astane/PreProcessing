{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial & Geospatial Data Preprocessing in Python\n",
    "#### Introduction\n",
    "#### Spatial and geospatial data contain location-based information that represents objects, events, or phenomena tied to the Earth's surface.\n",
    "\n",
    "#### Spatial data includes objects with coordinates (e.g., points, lines, polygons).\n",
    "#### Geospatial data contains location + attributes (e.g., population density, weather data).\n",
    "#### Examples of Spatial & Geospatial Data Applications:\n",
    "#### ‚úÖ Maps & Navigation ‚Äì GPS, Google Maps\n",
    "#### ‚úÖ Climate & Environment ‚Äì Weather forecasting\n",
    "#### ‚úÖ Urban Planning ‚Äì Infrastructure and transportation\n",
    "#### ‚úÖ Remote Sensing ‚Äì Satellite imagery analysis\n",
    "#### \n",
    "#### 1Ô∏è‚É£ Spatial Data Representation & Formats\n",
    "#### Geospatial data can be stored in different formats:\n",
    "#### \n",
    "#### Vector Data (Points, Lines, Polygons) ‚Üí Used for locations, roads, buildings\n",
    "#### Raster Data (Gridded pixels) ‚Üí Used for satellite images, elevation models\n",
    "#### Geospatial Databases: PostGIS, SpatiaLite, MongoDB (GeoJSON)\n",
    "#### üìå Example: Loading Geospatial Data in Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Load a shapefile (vector data)\n",
    "gdf = gpd.read_file(\"path/to/shapefile.shp\")\n",
    "\n",
    "# Display first rows\n",
    "print(gdf.head())\n",
    "\n",
    "# Plot the spatial data\n",
    "gdf.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2Ô∏è‚É£ Coordinate Reference Systems (CRS) & Reprojection\n",
    "#### Why?\n",
    "#### Geospatial data is often collected in different CRS (Coordinate Reference Systems).\n",
    "#### Reprojection is needed to align different datasets for spatial analysis.\n",
    "#### üìå Example: Reprojecting to a Common CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current CRS\n",
    "print(gdf.crs)\n",
    "\n",
    "# Convert to a different CRS (e.g., WGS 84)\n",
    "gdf = gdf.to_crs(epsg=4326)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of CRS:\n",
    "#### \n",
    "#### CRS\tDescription\tBest For\n",
    "#### EPSG:4326\tWGS 84 (lat, lon)\tGPS, Google Maps\n",
    "#### EPSG:3857\tWeb Mercator\tWeb mapping (OpenStreetMap)\n",
    "#### EPSG:32633\tUTM Zone 33N\tLocal, high-accuracy mapping\n",
    "#### 3Ô∏è‚É£ Handling Missing or Inaccurate Location Data\n",
    "#### Techniques:\n",
    "#### Remove invalid coordinates (out of bounds).\n",
    "#### Interpolate missing values (e.g., using neighboring points).\n",
    "#### Replace missing coordinates with nearest valid location.\n",
    "#### üìå Example: Removing Invalid Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove rows where latitude or longitude is missing\n",
    "gdf = gdf.dropna(subset=[\"latitude\", \"longitude\"])\n",
    "\n",
    "# Filter data within valid longitude/latitude range\n",
    "gdf = gdf[(gdf.longitude >= -180) & (gdf.longitude <= 180) &\n",
    "          (gdf.latitude >= -90) & (gdf.latitude <= 90)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4Ô∏è‚É£ Spatial Data Cleaning & Normalization\n",
    "#### Common Cleaning Steps:\n",
    "#### Remove duplicate geometries\n",
    "#### Fix invalid geometries (self-intersections, gaps)\n",
    "#### Convert inconsistent data types\n",
    "#### üìå Example: Fixing Invalid Geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.validation import make_valid\n",
    "\n",
    "# Fix invalid geometries\n",
    "gdf[\"geometry\"] = gdf[\"geometry\"].apply(make_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5Ô∏è‚É£ Geospatial Feature Engineering\n",
    "#### Spatial features improve machine learning models.\n",
    "#### \n",
    "#### (i) Distance Calculation\n",
    "#### Measure distance between points for applications like nearest neighbor search, travel time estimation.\n",
    "#### \n",
    "#### üìå Example: Compute Distance Between Two Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "\n",
    "# Define two locations (lat, lon)\n",
    "loc1 = (40.7128, -74.0060)  # New York\n",
    "loc2 = (34.0522, -118.2437)  # Los Angeles\n",
    "\n",
    "# Calculate distance in km\n",
    "distance_km = geodesic(loc1, loc2).km\n",
    "print(f\"Distance: {distance_km:.2f} km\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) Spatial Joins\n",
    "#### Combine datasets based on location.\n",
    "#### \n",
    "#### üìå Example: Join Points to Polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load city boundaries\n",
    "city_boundaries = gpd.read_file(\"city_boundaries.shp\")\n",
    "\n",
    "# Perform a spatial join\n",
    "points_with_city = gpd.sjoin(gdf, city_boundaries, how=\"left\", predicate=\"within\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Extracting Features from Spatial Data\n",
    "#### Feature\tDescription\tExample Usage\n",
    "#### Proximity\tDistance to nearest feature\tNearest hospital, road\n",
    "#### Spatial Density\tCount of features in a given area\tPopulation density\n",
    "#### Elevation\tHeight above sea level\tFlood prediction\n",
    "#### üìå Example: Compute Nearest Road Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "point_coords = gdf[[\"longitude\", \"latitude\"]].values\n",
    "road_coords = roads[[\"longitude\", \"latitude\"]].values\n",
    "\n",
    "# Build KDTree for fast nearest-neighbor search\n",
    "tree = cKDTree(road_coords)\n",
    "\n",
    "# Compute distance to nearest road\n",
    "distances, _ = tree.query(point_coords)\n",
    "gdf[\"nearest_road_distance\"] = distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6Ô∏è‚É£ Raster Data Processing\n",
    "#### Raster data (satellite images, elevation data) needs preprocessing for machine learning.\n",
    "#### \n",
    "#### üìå Example: Load and Process Satellite Image (Raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "\n",
    "# Open raster file\n",
    "with rasterio.open(\"satellite.tif\") as dataset:\n",
    "    image = dataset.read(1)  # Read first band\n",
    "    print(image.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7Ô∏è‚É£ Spatial Data Transformation\n",
    "#### Convert Vector Data to Grid (Rasterization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.features import rasterize\n",
    "\n",
    "# Convert vector polygons to raster\n",
    "rasterized = rasterize(shapes=gdf.geometry, out_shape=(100, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Raster Data to Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Extract values from raster\n",
    "rows, cols = np.where(image > 0)\n",
    "values = image[rows, cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of Spatial Preprocessing Techniques\n",
    "#### Method\tPurpose\tBest For\tPros\tCons\n",
    "#### CRS Reprojection\tConvert spatial data to a standard CRS\tMerging datasets\tNecessary for accuracy\tCan introduce distortions\n",
    "#### Missing Data Handling\tFix missing locations\tGPS data cleaning\tImproves completeness\tMay introduce bias\n",
    "#### Spatial Joins\tMerge datasets spatially\tAdding context\tEnhances dataset\tComputational cost\n",
    "#### Feature Engineering (Distance, Density)\tAdd meaningful features\tML models\tBoosts performance\tFeature selection needed\n",
    "#### Raster Processing\tHandle images/satellite data\tRemote sensing, climate data\tRicher representation\tLarge file sizes\n",
    "#### Final Thoughts\n",
    "#### Spatial data preprocessing is crucial for GIS, remote sensing, and ML applications.\n",
    "#### Coordinate transformation and data cleaning ensure consistency.\n",
    "#### Feature engineering (distances, densities, spatial joins) boosts machine learning models.\n",
    "#### Raster and vector processing enable advanced analysis.\n",
    "#### Would you like a deep dive into spatial machine learning techniques (e.g., spatial clustering, geospatial deep learning)? üöÄ\n",
    "\n",
    "#### Advanced Spatial & Geospatial Data Preprocessing\n",
    "#### In this section, we will cover advanced geospatial data preprocessing techniques with detailed explanations, Python examples, and comparisons.\n",
    "#### \n",
    "#### 1Ô∏è‚É£ Spatial Aggregation\n",
    "#### üîπ What is it?\n",
    "#### Spatial aggregation groups raw point-based data (latitude, longitude) into larger spatial units like:\n",
    "#### \n",
    "#### Zip codes, city districts, or states\n",
    "#### Hexagonal or square grids\n",
    "#### Administrative boundaries\n",
    "#### üîπ Why use Spatial Aggregation?\n",
    "#### ‚úÖ Reduces the granularity of data, making it easier to analyze\n",
    "#### ‚úÖ Improves interpretability by summarizing dense spatial data\n",
    "#### ‚úÖ Helps in data privacy by avoiding revealing exact locations\n",
    "#### \n",
    "#### üìå Example: Aggregating Data by Zip Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# Load raw point data (e.g., customer locations)\n",
    "points = gpd.read_file(\"customer_locations.shp\")\n",
    "\n",
    "# Load zip code boundaries (polygon shapefile)\n",
    "zip_codes = gpd.read_file(\"zip_codes.shp\")\n",
    "\n",
    "# Spatial join: Assign each point to a zip code\n",
    "points_with_zip = gpd.sjoin(points, zip_codes, how=\"left\", predicate=\"within\")\n",
    "\n",
    "# Aggregate customer count per zip code\n",
    "zip_agg = points_with_zip.groupby(\"zip_code\")[\"customer_id\"].count().reset_index()\n",
    "zip_agg.rename(columns={\"customer_id\": \"customer_count\"}, inplace=True)\n",
    "\n",
    "print(zip_agg.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üÜö Comparison of Aggregation Methods\n",
    "#### Method\tBest For\tPros\tCons\n",
    "#### Zip Codes / Administrative Boundaries\tCensus, business analysis\tMeaningful real-world areas\tIrregular shape sizes\n",
    "#### Hexagonal Grids (H3, Uber)\tClimate, mobility data\tEqual area, avoids bias\tComputational overhead\n",
    "#### Square Grids (Fishnet)\tRaster-based aggregation\tSimple and fast\tMay not align with natural boundaries\n",
    "#### 2Ô∏è‚É£ Feature Engineering for Geospatial Data\n",
    "#### üîπ What is it?\n",
    "#### Feature engineering extracts meaningful numerical features from spatial data to enhance machine learning models.\n",
    "#### \n",
    "#### üîπ Common Spatial Features\n",
    "#### ‚úÖ Distance to nearest key locations (e.g., distance to nearest hospital, store, road)\n",
    "#### ‚úÖ Spatial Autocorrelation (e.g., clustering of similar data values)\n",
    "#### ‚úÖ Density metrics (e.g., number of points in a given area)\n",
    "#### \n",
    "#### üìå Example: Compute Distance to Nearest Hospital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "import numpy as np\n",
    "\n",
    "# Convert hospital and customer locations to NumPy arrays\n",
    "hospitals_coords = hospitals[[\"longitude\", \"latitude\"]].values\n",
    "customer_coords = customers[[\"longitude\", \"latitude\"]].values\n",
    "\n",
    "# Build KDTree for fast nearest neighbor search\n",
    "tree = cKDTree(hospitals_coords)\n",
    "\n",
    "# Compute distance to nearest hospital\n",
    "distances, _ = tree.query(customer_coords)\n",
    "customers[\"nearest_hospital_distance\"] = distances\n",
    "\n",
    "print(customers.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìå Example: Compute Spatial Autocorrelation (Moran‚Äôs I)\n",
    "#### Spatial autocorrelation measures how similar values are across space.\n",
    "#### \n",
    "#### \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from esda.moran import Moran\n",
    "import libpysal as ps\n",
    "\n",
    "# Create spatial weights matrix (based on neighbors)\n",
    "w = ps.weights.KNN.from_dataframe(gdf, k=5)\n",
    "\n",
    "# Compute Moran's I (spatial autocorrelation)\n",
    "moran = Moran(gdf[\"price\"], w)\n",
    "print(f\"Moran's I: {moran.I}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üÜö Comparison of Spatial Feature Engineering Methods\n",
    "#### Method\tUsage\tPros\tCons\n",
    "#### Distance to Nearest Point (KDTree)\tUrban planning, travel time estimation\tFast & scalable\tNeeds preprocessing\n",
    "#### Density Metrics (Kernel Density Estimation)\tCrime mapping, customer clustering\tCaptures spatial intensity\tSensitive to bandwidth selection\n",
    "#### Spatial Autocorrelation (Moran‚Äôs I, Geary‚Äôs C)\tPattern detection, clustering\tMeasures spatial similarity\tNeeds statistical interpretation\n",
    "#### 3Ô∏è‚É£ Geospatial Interpolation\n",
    "#### üîπ What is it?\n",
    "#### Geospatial interpolation estimates missing or unknown values at unobserved locations using data from known points.\n",
    "#### \n",
    "#### üîπ Why use it?\n",
    "#### ‚úÖ Fills missing data gaps (e.g., estimating missing temperature values)\n",
    "#### ‚úÖ Creates continuous surfaces from scattered point data\n",
    "#### ‚úÖ Essential for environmental modeling (e.g., pollution, rainfall mapping)\n",
    "#### \n",
    "#### Interpolation Methods\n",
    "#### Method\tUsage\tPros\tCons\n",
    "#### Inverse Distance Weighting (IDW)\tQuick spatial estimation\tSimple & fast\tAssumes local influence\n",
    "#### Kriging (Ordinary, Universal, etc.)\tAdvanced geostatistical modeling\tAccounts for spatial trends\tComputationally intensive\n",
    "#### Spline Interpolation\tSmooth surfaces\tGood for gradual changes\tCan oversmooth sharp changes\n",
    "#### üìå Example: Inverse Distance Weighting (IDW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# Define known data points (coordinates & values)\n",
    "known_points = np.array([[0, 0, 10], [1, 1, 15], [2, 2, 20]])\n",
    "unknown_point = np.array([1.5, 1.5])  # Location where we estimate value\n",
    "\n",
    "# Compute inverse distance weights\n",
    "dists = distance.cdist([unknown_point], known_points[:, :2], metric='euclidean')\n",
    "weights = 1 / dists\n",
    "weights /= weights.sum()\n",
    "\n",
    "# Compute estimated value\n",
    "estimated_value = np.sum(weights * known_points[:, 2])\n",
    "print(f\"Estimated value at {unknown_point}: {estimated_value:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìå Example: Kriging Interpolation using PyKrige"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykrige.ok import OrdinaryKriging\n",
    "import numpy as np\n",
    "\n",
    "# Known points (x, y, value)\n",
    "x = np.array([0, 1, 2])\n",
    "y = np.array([0, 1, 2])\n",
    "values = np.array([10, 15, 20])\n",
    "\n",
    "# Create Kriging model\n",
    "OK = OrdinaryKriging(x, y, values, variogram_model=\"spherical\")\n",
    "\n",
    "# Predict at new point\n",
    "z, ss = OK.execute(\"points\", np.array([1.5]), np.array([1.5]))\n",
    "print(f\"Kriging estimated value: {z[0]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üÜö IDW vs. Kriging: When to Use Each?\n",
    "#### Method\tBest For\tPros\tCons\n",
    "#### IDW\tQuick estimates with local influence\tSimple & fast\tDoesn't model global trends\n",
    "#### Kriging\tComplex spatial relationships\tStatistically rigorous\tComputationally expensive\n",
    "#### Final Thoughts\n",
    "#### ‚úÖ Spatial aggregation is useful for simplifying raw coordinate data into meaningful regions\n",
    "#### ‚úÖ Feature engineering enhances predictive models by adding spatial relationships\n",
    "#### ‚úÖ Geospatial interpolation fills missing values and creates continuous spatial surfaces"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
