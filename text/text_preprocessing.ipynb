{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 1. Key Preprocessing Techniques for Text Data\n",
    "## 1.1 Tokenization\n",
    "#### üîπ Splits text into individual words (word-level) or subwords/characters (subword/character-level).\n",
    "#### üîπ Helps in transforming text into a structured format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/astane/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Tokens: ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'amazing', '!', 'Let', \"'s\", 'learn', 'it', '.']\n",
      "Sentence Tokens: ['Natural Language Processing (NLP) is amazing!', \"Let's learn it.\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "text = \"Natural Language Processing (NLP) is amazing! Let's learn it.\"\n",
    "\n",
    "# Word Tokenization\n",
    "word_tokens = word_tokenize(text)\n",
    "print(\"Word Tokens:\", word_tokens)\n",
    "\n",
    "# Sentence Tokenization\n",
    "sent_tokens = sent_tokenize(text)\n",
    "print(\"Sentence Tokens:\", sent_tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#üîπ Comparison:\n",
    "\n",
    "#### Method\tPros\tCons\n",
    "#### Word Tokenization\tSimple, easy to use\tDoesn't handle multi-word expressions\n",
    "#### Subword Tokenization\tUseful for rare words\tIncreases complexity\n",
    "#### Sentence Tokenization\tPreserves sentence context\tNot useful for word-based models\n",
    "#### 1.2 Removing Stopwords\n",
    "#### üîπ Stopwords (e.g., \"the\", \"is\", \"in\") do not contribute to the meaning of text in most cases and can be removed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/astane/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Words: ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'amazing', '!', 'Let', \"'s\", 'learn', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filtered_words = [word for word in word_tokens if word.lower() not in stop_words]\n",
    "print(\"Filtered Words:\", filtered_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#üîπ Comparison:\n",
    "\n",
    "#### Approach\tPros\tCons\n",
    "#### Remove Stopwords\tReduces noise and model size\tSome stopwords are important for meaning\n",
    "#### Keep Stopwords\tRetains full meaning\tMay add unnecessary complexity\n",
    "#### 1.3 Stemming and Lemmatization\n",
    "#### üîπ Stemming: Reduces words to their base/root form (e.g., \"running\" ‚Üí \"run\").\n",
    "#### üîπ Lemmatization: Converts words to their dictionary form (e.g., \"better\" ‚Üí \"good\").\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed: run\n",
      "Lemmatized: run\n",
      "Stemmed: best\n",
      "Lemmatized: best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/astane/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "word1 = \"running\"\n",
    "word2 = \"best\"\n",
    "\n",
    "print(\"Stemmed:\", stemmer.stem(word1))\n",
    "print(\"Lemmatized:\", lemmatizer.lemmatize(word1, pos='v'))\n",
    "\n",
    "print(\"Stemmed:\", stemmer.stem(word2))\n",
    "print(\"Lemmatized:\", lemmatizer.lemmatize(word2, pos='v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#üîπ Comparison:\n",
    "\n",
    "#### Method\tPros\tCons\n",
    "#### Stemming\tFast, simple\tCan create non-existent words (\"goose\" ‚Üí \"goos\")\n",
    "#### Lemmatization\tMore accurate\tSlower, needs POS tagging\n",
    "#### 1.4 Vectorization (Converting Text to Numeric Form)\n",
    "#### Since ML models require numerical input, we convert text into numerical format using:\n",
    "\n",
    "#### Bag of Words (BoW)\n",
    "#### TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "#### Word Embeddings (Word2Vec, GloVe, FastText)\n",
    "#### Transformers (BERT, GPT)\n",
    "#### 1.4.1 Bag of Words (BoW)\n",
    "#### BoW converts text into a matrix where each row is a sentence, and each column represents a word.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['great' 'is' 'language' 'love' 'natural' 'nlp' 'processing']\n",
      "BoW Matrix:\n",
      " [[0 0 1 1 1 0 1]\n",
      " [1 1 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text_data = [\"I love natural language processing\", \"NLP is great\"]\n",
    "vectorizer = CountVectorizer()\n",
    "bow_matrix = vectorizer.fit_transform(text_data)\n",
    "\n",
    "print(\"Vocabulary:\", vectorizer.get_feature_names_out())\n",
    "print(\"BoW Matrix:\\n\", bow_matrix.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### üîπ Pros & Cons:\n",
    "#### ‚úÖ Simple, effective for small datasets\n",
    "#### ‚ùå Ignores word order and meaning\n",
    "\n",
    "#### 1.4.2 TF-IDF\n",
    "#### TF-IDF assigns importance to words based on frequency in a document vs. all documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix:\n",
      " [[0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.33333333\n",
      "  0.33333333 0.33333333 0.33333333]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform([text])\n",
    "\n",
    "print(\"TF-IDF Matrix:\\n\", tfidf_matrix.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîπ Pros & Cons:\n",
    "#### ‚úÖ Reduces weight of common words, improves performance\n",
    "#### ‚ùå Still ignores word order\n",
    "\n",
    "#### 1.4.3 Word Embeddings (Word2Vec, GloVe)\n",
    "#### Embeddings capture the meaning of words in a dense vector space.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Vector for 'NLP': [-0.00536227  0.00236431  0.0510335   0.09009273 -0.0930295  -0.07116809\n",
      "  0.06458873  0.08972988 -0.05015428 -0.03763372]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Example sentences\n",
    "sentences = [[\"I\", \"love\", \"NLP\"], [\"NLP\", \"is\", \"amazing\"]]\n",
    "\n",
    "# Train a simple Word2Vec model\n",
    "model = Word2Vec(sentences, vector_size=10, min_count=1, workers=4)\n",
    "\n",
    "# Get embedding for 'NLP'\n",
    "print(\"Word Vector for 'NLP':\", model.wv['NLP'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîπ Pros & Cons:\n",
    "#### ‚úÖ Captures semantic meaning, works well for deep learning\n",
    "#### ‚ùå Needs large datasets, computationally expensive\n",
    "\n",
    "#### 1.4.4 Transformer-Based Embeddings (BERT)\n",
    "#### üîπ Pretrained transformer models (e.g., BERT, GPT) generate context-aware embeddings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2404d6c389d944d09a962721fbdbc30e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0ca594fc5424883a869e04edef39ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9888ba3f6264ac78bd8089dc05bfae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd1e776b93ac4761aeb2a41950a5b439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319f4656e1f2420181a806ad172e3661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Embedding Shape: torch.Size([1, 8, 768])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize input text\n",
    "inputs = tokenizer(\"Natural Language Processing is fun!\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Extract last hidden state\n",
    "embeddings = outputs.last_hidden_state\n",
    "print(\"BERT Embedding Shape:\", embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### üîπ Pros & Cons:\n",
    "#### ‚úÖ Context-aware, powerful for NLP\n",
    "#### ‚ùå Computationally expensive\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
